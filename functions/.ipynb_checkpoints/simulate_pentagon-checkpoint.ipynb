{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09ed4d83-7343-411b-aeca-2293cebad711",
   "metadata": {},
   "source": [
    "# Simulate_pentagon.ipynb\n",
    "\n",
    "## Purpose\n",
    "This notebook encompasses the generation of synthetic drawings of intersecting pentagons, as well as the prediction of global cognitive scores given the synthetic images.\n",
    "\n",
    "## Method\n",
    "The simulator employs eight parameters, including (1) angle distortion, (2) line waviness, (3) line width, (4) the number of vertices, (5) alignment of two pentagons, (6) the distance between pentagons, (7) pentagon size, and (8) size equality. For each value of the primary parameter tested, we generated 20 images with slight variations by randomly varying the remaining parameters within a small range around regular pentagons. The generated images were then supplied to ten deep learning models, each of which had been trained using a distinct subset of data.\n",
    "\n",
    "\n",
    "## Result\n",
    "All results can be found within the output directory. The list of parameters utilized for generating each image is stored as param.txt, and the predicted cognitive values for the simulated images are stored as {model_name}.txt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e75a06-e62b-4e59-b019-f1678157c15a",
   "metadata": {},
   "source": [
    "## Local library import\n",
    "We import all the required local libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb9d75bd-044c-4a89-8f14-8a814f05cbc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import copy\n",
    "import time\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np\n",
    "import munch\n",
    "import matplotlib.pyplot\n",
    "import matplotlib\n",
    "import json\n",
    "import imgaug as ia\n",
    "import imgaug as ia\n",
    "import imgaug\n",
    "import h5py\n",
    "import glob\n",
    "import gc\n",
    "import argparse\n",
    "from torchvision import models, transforms\n",
    "from torch.utils import data\n",
    "from simulate_pentagon import simulate_pentagon\n",
    "from PIL import Image\n",
    "from imgaug import augmenters as iaa\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba186aba-08a0-46e2-acd0-42a7b0ba31ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define Functions\n",
    "In this section, we outline the local functions utilized for the analysis.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85c042d0-c634-4550-8414-6c44cec06f56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialize_model(model_name, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "    num_classes = 1\n",
    "\n",
    "    if ('resnet' in model_name) & (not ('wide' in model_name)):\n",
    "        if model_name == \"resnet18\":\n",
    "            \"\"\" Resnet18\n",
    "            \"\"\"\n",
    "            model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        elif model_name == \"resnet34\":\n",
    "            \"\"\" Resnet34\n",
    "            \"\"\"\n",
    "            model_ft = models.resnet34(pretrained=use_pretrained)\n",
    "        elif model_name == \"resnet50\":\n",
    "            \"\"\" Resnet50\n",
    "            \"\"\"\n",
    "            model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "        elif model_name == \"resnet101\":\n",
    "            \"\"\" Resnet101\n",
    "            \"\"\"\n",
    "            model_ft = models.resnet101(pretrained=use_pretrained)\n",
    "        elif model_name == \"resnet152\":\n",
    "            \"\"\" Resnet152\n",
    "            \"\"\"\n",
    "            model_ft = models.resnet152(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "    elif model_name == \"googlenet\":\n",
    "        \"\"\" googlenet\n",
    "        \"\"\"\n",
    "        model_ft = models.googlenet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "    elif 'wide_resnet' in model_name:\n",
    "        if model_name == \"wide_resnet50_2\":\n",
    "            \"\"\" wide_resnet50_2\n",
    "            \"\"\"\n",
    "            model_ft = models.wide_resnet50_2(pretrained=use_pretrained)\n",
    "        elif model_name == \"wide_resnet101_2\":\n",
    "            \"\"\" wide_resnet101_2\n",
    "            \"\"\"\n",
    "            model_ft = models.wide_resnet101_2(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "    elif 'resnext' in model_name:\n",
    "        if model_name == \"resnext50_32x4d\":\n",
    "            \"\"\" resnext50_32x4d\n",
    "            \"\"\"\n",
    "            model_ft = models.resnext50_32x4d(pretrained=use_pretrained)\n",
    "        elif model_name == \"resnext101_32x8d\":\n",
    "            \"\"\" resnext101_32x8d\n",
    "            \"\"\"\n",
    "            model_ft = models.resnext101_32x8d(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "    elif 'mnasnet' in model_name:\n",
    "        if model_name == \"mnasnet0_5\":\n",
    "            \"\"\" mnasnet0_5\n",
    "            \"\"\"\n",
    "            model_ft = models.mnasnet0_5(pretrained=use_pretrained)\n",
    "        elif model_name == \"mnasnet0_75\":\n",
    "            \"\"\" mnasnet0_75\n",
    "            \"\"\"\n",
    "            model_ft = models.mnasnet0_75(pretrained=use_pretrained)\n",
    "        elif model_name == \"mnasnet1_0\":\n",
    "            \"\"\" mnasnet1_0\n",
    "            \"\"\"\n",
    "            model_ft = models.mnasnet1_0(pretrained=use_pretrained)\n",
    "        elif model_name == \"mnasnet1_3\":\n",
    "            \"\"\" mnasnet1_3\n",
    "            \"\"\"\n",
    "            model_ft = models.mnasnet1_3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[1].in_features\n",
    "        model_ft.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "    elif 'mobilenet_v3' in model_name:\n",
    "        if model_name == \"mobilenet_v3_large\":\n",
    "            \"\"\" mobilenet_v3_large\n",
    "            \"\"\"\n",
    "            model_ft = models.mobilenet_v3_large(pretrained=use_pretrained)\n",
    "        elif model_name == \"mobilenet_v3_small\":\n",
    "            \"\"\" mobilenet_v3_small\n",
    "            \"\"\"\n",
    "            model_ft = models.mobilenet_v3_small(pretrained=use_pretrained)\n",
    "            \n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[3].in_features\n",
    "        model_ft.classifier[3] = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "    elif 'mobilenet_v2' in model_name:\n",
    "        model_ft = models.mobilenet_v2(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.classifier[1].in_features\n",
    "        model_ft.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "    elif 'vgg' in model_name:\n",
    "        if model_name == \"vgg11\":\n",
    "            \"\"\" VGG11\n",
    "            \"\"\"\n",
    "            model_ft = models.vgg11(pretrained=use_pretrained)\n",
    "        elif model_name == \"vgg11_bn\":\n",
    "            \"\"\" VGG11_bn\n",
    "            \"\"\"\n",
    "            model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        elif model_name == \"vgg13\":\n",
    "            \"\"\" VGG13\n",
    "            \"\"\"\n",
    "            model_ft = models.vgg13(pretrained=use_pretrained)\n",
    "        elif model_name == \"vgg13_bn\":\n",
    "            \"\"\" VGG13_bn\n",
    "            \"\"\"\n",
    "            model_ft = models.vgg13_bn(pretrained=use_pretrained)\n",
    "        elif model_name == \"vgg16\":\n",
    "            \"\"\" VGG16\n",
    "            \"\"\"\n",
    "            model_ft = models.vgg16(pretrained=use_pretrained)\n",
    "        elif model_name == \"vgg16_bn\":\n",
    "            \"\"\" VGG16_bn\n",
    "            \"\"\"\n",
    "            model_ft = models.vgg16_bn(pretrained=use_pretrained)\n",
    "        elif model_name == \"vgg19\":\n",
    "            \"\"\" VGG19\n",
    "            \"\"\"\n",
    "            model_ft = models.vgg19(pretrained=use_pretrained)\n",
    "        elif model_name == \"vgg19_bn\":\n",
    "            \"\"\" VGG19_bn\n",
    "            \"\"\"\n",
    "            model_ft = models.vgg19_bn(pretrained=use_pretrained)\n",
    "            \n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "    elif 'efficientnet' in model_name:\n",
    "        if model_name == \"efficientnet_b0\":\n",
    "            \"\"\" efficientnet_b0\n",
    "            \"\"\"\n",
    "            model_ft = models.efficientnet_b0(pretrained=use_pretrained)\n",
    "        elif model_name == \"efficientnet_b1\":\n",
    "            \"\"\" efficientnet_b1\n",
    "            \"\"\"\n",
    "            model_ft = models.efficientnet_b1(pretrained=use_pretrained)\n",
    "        elif model_name == \"efficientnet_b2\":\n",
    "            \"\"\" efficientnet_b2\n",
    "            \"\"\"\n",
    "            model_ft = models.efficientnet_b2(pretrained=use_pretrained)\n",
    "        elif model_name == \"efficientnet_b3\":\n",
    "            \"\"\" efficientnet_b3\n",
    "            \"\"\"\n",
    "            model_ft = models.efficientnet_b3(pretrained=use_pretrained)\n",
    "        elif model_name == \"efficientnet_b4\":\n",
    "            \"\"\" efficientnet_b4\n",
    "            \"\"\"\n",
    "            model_ft = models.efficientnet_b4(pretrained=use_pretrained)\n",
    "        elif model_name == \"efficientnet_b5\":\n",
    "            \"\"\" efficientnet_b5\n",
    "            \"\"\"\n",
    "            model_ft = models.efficientnet_b5(pretrained=use_pretrained)\n",
    "        elif model_name == \"efficientnet_b6\":\n",
    "            \"\"\" efficientnet_b6\n",
    "            \"\"\"\n",
    "            model_ft = models.efficientnet_b6(pretrained=use_pretrained)\n",
    "        elif model_name == \"efficientnet_b7\":\n",
    "            \"\"\" efficientnet_b7\n",
    "            \"\"\"\n",
    "            model_ft = models.efficientnet_b7(pretrained=use_pretrained)\n",
    "            \n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[1].in_features\n",
    "        model_ft.classifier[1] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "    elif 'regnet' in model_name:\n",
    "        if model_name == \"regnet_y_400mf\":\n",
    "            \"\"\" regnet_y_400mf\n",
    "            \"\"\"\n",
    "            model_ft = models.regnet_y_400mf(pretrained=use_pretrained)\n",
    "        elif model_name == \"regnet_y_800mf\":\n",
    "            \"\"\" regnet_y_800mf\n",
    "            \"\"\"\n",
    "            model_ft = models.regnet_y_800mf(pretrained=use_pretrained)\n",
    "        elif model_name == \"regnet_y_1_6gf\":\n",
    "            \"\"\" regnet_y_1_6gf\n",
    "            \"\"\"\n",
    "            model_ft = models.regnet_y_1_6gf(pretrained=use_pretrained)\n",
    "        elif model_name == \"regnet_y_3_2gf\":\n",
    "            \"\"\" regnet_y_3_2gf\n",
    "            \"\"\"\n",
    "            model_ft = models.regnet_y_3_2gf(pretrained=use_pretrained)\n",
    "        elif model_name == \"regnet_y_8gf\":\n",
    "            \"\"\" regnet_y_8gf\n",
    "            \"\"\"\n",
    "            model_ft = models.regnet_y_8gf(pretrained=use_pretrained)\n",
    "        elif model_name == \"regnet_y_16gf\":\n",
    "            \"\"\" regnet_y_16gf\n",
    "            \"\"\"\n",
    "            model_ft = models.regnet_y_16gf(pretrained=use_pretrained)\n",
    "        elif model_name == \"regnet_y_32gf\":\n",
    "            \"\"\" regnet_y_32gf\n",
    "            \"\"\"\n",
    "            model_ft = models.regnet_y_32gf(pretrained=use_pretrained)\n",
    "        elif model_name == \"regnet_x_400mf\":\n",
    "            \"\"\" regnet_x_400mf\n",
    "            \"\"\"\n",
    "            model_ft = models.regnet_x_400mf(pretrained=use_pretrained)\n",
    "        elif model_name == \"regnet_x_800mf\":\n",
    "            \"\"\" regnet_x_800mf\n",
    "            \"\"\"\n",
    "            model_ft = models.regnet_x_800mf(pretrained=use_pretrained)\n",
    "        elif model_name == \"regnet_x_1_6gf\":\n",
    "            \"\"\" regnet_x_1_6gf\n",
    "            \"\"\"\n",
    "            model_ft = models.regnet_x_1_6gf(pretrained=use_pretrained)\n",
    "        elif model_name == \"regnet_x_3_2gf\":\n",
    "            \"\"\" regnet_x_3_2gf\n",
    "            \"\"\"\n",
    "            model_ft = models.regnet_x_3_2gf(pretrained=use_pretrained)\n",
    "        elif model_name == \"regnet_x_8gf\":\n",
    "            \"\"\" regnet_x_8gf\n",
    "            \"\"\"\n",
    "            model_ft = models.regnet_x_8gf(pretrained=use_pretrained)\n",
    "        elif model_name == \"regnet_x_16gf\":\n",
    "            \"\"\" regnet_x_16gf\n",
    "            \"\"\"\n",
    "            model_ft = models.regnet_x_16gf(pretrained=use_pretrained)\n",
    "        elif model_name == \"regnet_x_32gf\":\n",
    "            \"\"\" regnet_x_32gf\n",
    "            \"\"\"\n",
    "            model_ft = models.regnet_x_32gf(pretrained=use_pretrained)\n",
    "            \n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "    elif model_name == \"squeezenet1_1\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_1(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet121\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "class ImgAugTransform:\n",
    "    def __init__(self,params):\n",
    "        \n",
    "        aug_list = []\n",
    "        if params['Fliplr']:\n",
    "            aug_list.append(iaa.Fliplr(0.5))\n",
    "        if params['Flipud']:\n",
    "            aug_list.append(iaa.Flipud(0.5))\n",
    "        if params['Rot90']:\n",
    "            aug_list.append(iaa.Rot90((0,3)))\n",
    "        if params['Affine']:\n",
    "            aug_list.append(iaa.Sometimes(params['aff_sometimes'],\n",
    "                                          iaa.Affine(translate_percent={'x':(-params['aff_translate'],\n",
    "                                                                             params['aff_translate']),\n",
    "                                                                        'y':(-params['aff_translate'],\n",
    "                                                                             params['aff_translate'])},\n",
    "                                                     rotate=(-params['aff_rotate'], params['aff_rotate']),\n",
    "                                                     cval=255)))\n",
    "        aug_list2 = []\n",
    "        if params['CBS']:\n",
    "            aug_list2.append(iaa.SomeOf((0, 3), [\n",
    "                iaa.GammaContrast((0, 2.0)),\n",
    "                iaa.GaussianBlur(sigma=(0, 3.0)),\n",
    "                iaa.Sharpen((0, 1))\n",
    "            ],random_order=True))\n",
    "        if params['AdditiveGaussianNoise']:\n",
    "            aug_list2.append(iaa.AdditiveGaussianNoise(scale=(0, 0.02*255)))\n",
    "        if params['SaltAndPepper']:\n",
    "            aug_list2.append(iaa.SaltAndPepper(0.05))\n",
    "        \n",
    "        self.aug = iaa.Sequential(aug_list, \n",
    "                                  random_order=True)\n",
    "        self.aug2 = iaa.Sequential(aug_list2, \n",
    "                                  random_order=True)\n",
    "    def __call__(self, img):\n",
    "        img = np.array(img)\n",
    "        img = self.aug.augment_image(img)\n",
    "        img = self.aug2.augment_image(img)\n",
    "        return img\n",
    "\n",
    "def define_network(config):\n",
    "    net, input_size = initialize_model(config.model_name, False, use_pretrained=True)\n",
    "    net.to(config.device)\n",
    "    return net, input_size\n",
    "\n",
    "def run_exp(net,param_list,label,param_range,config):\n",
    "    if not os.path.exists(config['output_dir']+label+\"/images/\"):\n",
    "        os.makedirs(config['output_dir']+label+\"/images/\")\n",
    "    image = [simulate_pentagon(**param_list[i]) for i in range(len(param_list))]\n",
    "    pd.DataFrame(param_list).to_csv(config['output_dir']+label+\"/param.txt\",sep=\"\\t\")\n",
    "    for i in range(len(image)):\n",
    "        image[i].save(config['output_dir']+label+\"/images/\"+str(i)+\".png\", format=\"png\")\n",
    "    ia.seed(1234)\n",
    "    image = torch.stack([transform_img(Image.fromarray(transforms_imgaug(image[i]))) for i in range(len(image))])\n",
    "\n",
    "    for j in range(1,config[\"num_models\"]+1):\n",
    "        #print(j)\n",
    "        # Load model\n",
    "        config[\"model_loc\"]=\"../models/vgg19_bn-\"+str(j)+\"_model.pth\"\n",
    "        net.load_state_dict(torch.load(config[\"model_loc\"],\n",
    "                                       map_location=config.device))\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            out = net(image.cuda())\n",
    "            out = out.cpu().detach().numpy()\n",
    "        pd.DataFrame({'n':param_range,\n",
    "                     'pred':out[:,0]}).to_csv(config['output_dir']+label+\"/\"+os.path.basename(config['model_loc']).replace(\".pth\",\".txt\"),\n",
    "               sep=\"\\t\")\n",
    "    del image\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac7c81d-12fc-4f72-8f7e-5f52d53e0e0d",
   "metadata": {},
   "source": [
    "# Parameter Specification\n",
    "In this section, we establish all crucial parameters for our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5dafe72-299a-44cd-8eab-5917534bd9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'model_name': \"vgg19_bn\",\n",
    "    'batch_size': 32,\n",
    "    'Fliplr':True,\n",
    "    'Flipud':True,\n",
    "    'Rot90':True,\n",
    "    'Affine':True,\n",
    "    'aff_sometimes':0.9,\n",
    "    'aff_translate':0.1,\n",
    "    'aff_rotate':10,\n",
    "    'CBS':True,\n",
    "    'AdditiveGaussianNoise':False,\n",
    "    'SaltAndPepper':False,\n",
    "    'output_dir': \"../results/simulate_pentagon/\",\n",
    "    'num_models':10\n",
    "}\n",
    "config=munch.Munch(config)\n",
    "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4ca18f-34bd-4d6f-9bef-6edbd36c8542",
   "metadata": {},
   "source": [
    "# Model Architecture Loading\n",
    "In this step, we import a model from torchvision and adjust the final output layer accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9e6d056-22c5-4ebb-8e2b-8dd1d242596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net, input_size = define_network(config)\n",
    "config.input_size = input_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a51819-d8ba-4201-a8ed-49e0c03839d9",
   "metadata": {},
   "source": [
    "# Image Processing Pipeline Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3262601-867b-4e0c-90a3-012ae0406f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_img = transforms.Compose([transforms.Resize((config.input_size,config.input_size)),\n",
    "                                             transforms.ToTensor(),\n",
    "                                             transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                                  [0.229, 0.224, 0.225])])\n",
    "transforms_imgaug = ImgAugTransform(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929af822-1560-4418-939c-cdf5389c36ac",
   "metadata": {},
   "source": [
    "# Simulation Experiment Execution\n",
    "In this section, we execute the pentagon simulation and predict the global cognitive score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faeefd0f-6111-42ef-bac9-4ac6457de2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_vertex\n",
      "pentagon_size\n",
      "pentagon_distortion\n",
      "line_width\n",
      "pentagon_overlap\n",
      "pentagon_alignment\n",
      "size_equality\n",
      "line_randomness\n"
     ]
    }
   ],
   "source": [
    "### n_vertex ################\n",
    "label=\"n_vertex\"\n",
    "print(label)\n",
    "np.random.seed(1234)\n",
    "param_range = np.repeat(np.arange(3, 11, 1),20)\n",
    "param_list = [{'n':i,\n",
    "  'pentagon_size' : np.random.uniform(0.8,1.2),\n",
    "  'rot' : np.random.uniform(0,5),\n",
    "  'lw' : np.random.uniform(1,2),\n",
    "  'dist' : np.random.uniform(0.8,1.2),\n",
    "  'rot_right': np.random.uniform(-10,10),\n",
    "  'size_right':np.random.uniform(0.8,1.2),\n",
    "  'rot_both':0,\n",
    "  'line_randomness':np.random.uniform(1,2)} for i in param_range]\n",
    "run_exp(net,param_list,label,param_range,config)\n",
    "\n",
    "### pentagon_size ################\n",
    "label=\"pentagon_size\"\n",
    "print(label)\n",
    "np.random.seed(1234)\n",
    "param_range = np.repeat(np.arange(0.5, 2.1, 0.2),20)\n",
    "param_list = [{'n':5,\n",
    "  'pentagon_size' : i,\n",
    "  'rot' : np.random.uniform(0,5),\n",
    "  'lw' : np.random.uniform(1,2),\n",
    "  'dist' : np.random.uniform(0.8,1.2),\n",
    "  'rot_right': np.random.uniform(-10,10),\n",
    "  'size_right':np.random.uniform(0.8,1.2),\n",
    "  'rot_both':0,\n",
    "  'line_randomness':np.random.uniform(1,2)} for i in param_range]\n",
    "run_exp(net,param_list,label,param_range,config)\n",
    "\n",
    "### pentagon_distortion ################\n",
    "label=\"pentagon_distortion\"\n",
    "print(label)\n",
    "np.random.seed(1234)\n",
    "param_range = np.repeat(np.arange(0, 24, 3),20)\n",
    "param_list = [{'n':5,\n",
    "  'pentagon_size' : np.random.uniform(0.8,1.2),\n",
    "  'rot' : i,\n",
    "  'lw' : np.random.uniform(1,2),\n",
    "  'dist' : np.random.uniform(0.8,1.2),\n",
    "  'rot_right': np.random.uniform(-10,10),\n",
    "  'size_right':np.random.uniform(0.8,1.2),\n",
    "  'rot_both':0,\n",
    "  'line_randomness':np.random.uniform(1,2)} for i in param_range]\n",
    "run_exp(net,param_list,label,param_range,config)\n",
    "\n",
    "### line_width ################\n",
    "label=\"line_width\"\n",
    "print(label)\n",
    "np.random.seed(1234)\n",
    "param_range = np.repeat(np.arange(0.1, 2.4, 0.3),20)\n",
    "param_list = [{'n':5,\n",
    "  'pentagon_size' : np.random.uniform(0.8,1.2),\n",
    "  'rot' : np.random.uniform(0,5),\n",
    "  'lw' : i,\n",
    "  'dist' : np.random.uniform(0.8,1.2),\n",
    "  'rot_right': np.random.uniform(-10,10),\n",
    "  'size_right':np.random.uniform(0.8,1.2),\n",
    "  'rot_both':0,\n",
    "  'line_randomness':np.random.uniform(1,2)} for i in param_range]\n",
    "run_exp(net,param_list,label,param_range,config)\n",
    "\n",
    "### pentagon_overlap ################\n",
    "label=\"pentagon_overlap\"\n",
    "print(label)\n",
    "np.random.seed(1234)\n",
    "param_range = np.repeat(np.arange(0.5, 1.6, 0.15),20)\n",
    "param_list = [{'n':5,\n",
    "  'pentagon_size' : np.random.uniform(0.8,1.2),\n",
    "  'rot' : np.random.uniform(0,5),\n",
    "  'lw' : np.random.uniform(1,2),\n",
    "  'dist' : i,\n",
    "  'rot_right': np.random.uniform(-10,10),\n",
    "  'size_right':np.random.uniform(0.8,1.2),\n",
    "  'rot_both':0,\n",
    "  'line_randomness':np.random.uniform(1,2)} for i in param_range]\n",
    "run_exp(net,param_list,label,param_range,config)\n",
    "\n",
    "### pentagon_alignment ################\n",
    "label=\"pentagon_alignment\"\n",
    "print(label)\n",
    "np.random.seed(1234)\n",
    "param_range = np.repeat(np.arange(0, 12*8, 12),20)\n",
    "param_list = [{'n':5,\n",
    "  'pentagon_size' : np.random.uniform(0.8,1.2),\n",
    "  'rot' : np.random.uniform(0,5),\n",
    "  'lw' : np.random.uniform(1,2),\n",
    "  'dist' : np.random.uniform(0.8,1.2),\n",
    "  'rot_right': i,\n",
    "  'size_right':np.random.uniform(0.8,1.2),\n",
    "  'rot_both':0,\n",
    "  'line_randomness':np.random.uniform(1,2)} for i in param_range]\n",
    "run_exp(net,param_list,label,param_range,config)\n",
    "\n",
    "### size_equality ################\n",
    "label=\"size_equality\"\n",
    "print(label)\n",
    "np.random.seed(1234)\n",
    "param_range = np.repeat(np.arange(0.5, 2.1, 0.2),20)\n",
    "param_list = [{'n':5,\n",
    "  'pentagon_size' : 1,#np.sqrt((1+i**2)/2),\n",
    "  'rot' : np.random.uniform(0,5),\n",
    "  'lw' : np.random.uniform(1,2),\n",
    "  'dist' : np.random.uniform(0.8,1.2),\n",
    "  'rot_right': np.random.uniform(-10,10),\n",
    "  'size_right':i,\n",
    "  'rot_both':0,\n",
    "  'line_randomness':np.random.uniform(1,2)} for i in param_range]\n",
    "run_exp(net,param_list,label,param_range,config)\n",
    "\n",
    "### line_randomness ################\n",
    "label=\"line_randomness\"\n",
    "print(label)\n",
    "np.random.seed(1234)\n",
    "param_range = np.repeat(np.arange(1, 23, 3),20)\n",
    "param_list = [{'n':5,\n",
    "  'pentagon_size' : np.random.uniform(0.8,1.2),\n",
    "  'rot' : np.random.uniform(0,5),\n",
    "  'lw' : np.random.uniform(1,2),\n",
    "  'dist' : np.random.uniform(0.8,1.2),\n",
    "  'rot_right': np.random.uniform(-10,10),\n",
    "  'size_right':np.random.uniform(0.8,1.2),\n",
    "  'rot_both':0,\n",
    "  'line_randomness':i} for i in param_range]\n",
    "run_exp(net,param_list,label,param_range,config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:d6]",
   "language": "python",
   "name": "conda-env-d6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
